{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from scipy.stats import poisson\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(dataset, original_granularity, new_granularity):\n",
    "    df = dataset\n",
    "    num_buckets = int(original_granularity/new_granularity)\n",
    "\n",
    "    feature1 = \"{} Seconds\".format(new_granularity)\n",
    "    feature2 = \"Flow (Veh/{} Seconds)\".format(new_granularity)\n",
    "    cols = [feature1, feature2]\n",
    "    new_df = pd.DataFrame(columns=cols)\n",
    "    idx = 0\n",
    "    for i in range(100):\n",
    "        start_time = df[i][0]\n",
    "        target_flow = df[i][1]\n",
    "        dt = parser.parse(start_time)\n",
    "        remaining_flow = target_flow\n",
    "        \n",
    "        for n in range(num_buckets-1):\n",
    "            random_flow = int(target_flow/num_buckets)\n",
    "            remaining_flow -= random_flow\n",
    "            td = n*timedelta(seconds=new_granularity)\n",
    "            time = dt + td \n",
    "            data = pd.DataFrame({feature1: time, feature2: random_flow}, index=[idx])            \n",
    "            new_df = new_df.append({feature1: time, feature2: random_flow}, ignore_index=True)\n",
    "            idx += 1\n",
    "\n",
    "        td = (num_buckets)*timedelta(seconds=new_granularity)\n",
    "        time = dt + td\n",
    "        random_flow = remaining_flow\n",
    "        data = pd.DataFrame({feature1: time, feature2: random_flow}, index=[idx])\n",
    "        new_df = new_df.append(data, ignore_index=True)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/redondo/test.csv')\n",
    "dataset = np.array(dataset)\n",
    "original_granularity = 300\n",
    "new_granularity = 30\n",
    "new_df = subsample(dataset, original_granularity, new_granularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             30 Seconds Flow (Veh/30 Seconds)\n",
      "0   2016-04-03 00:00:00                     1\n",
      "1   2016-04-03 00:00:30                     1\n",
      "2   2016-04-03 00:01:00                     1\n",
      "3   2016-04-03 00:01:30                     1\n",
      "4   2016-04-03 00:02:00                     1\n",
      "5   2016-04-03 00:02:30                     1\n",
      "6   2016-04-03 00:03:00                     1\n",
      "7   2016-04-03 00:03:30                     1\n",
      "8   2016-04-03 00:04:00                     1\n",
      "9   2016-04-03 00:05:00                     7\n",
      "10  2016-04-03 00:05:00                     1\n",
      "11  2016-04-03 00:05:30                     1\n",
      "12  2016-04-03 00:06:00                     1\n",
      "13  2016-04-03 00:06:30                     1\n",
      "14  2016-04-03 00:07:00                     1\n",
      "15  2016-04-03 00:07:30                     1\n",
      "16  2016-04-03 00:08:00                     1\n",
      "17  2016-04-03 00:08:30                     1\n",
      "18  2016-04-03 00:09:00                     1\n",
      "19  2016-04-03 00:10:00                     1\n",
      "20  2016-04-03 00:10:00                     1\n",
      "21  2016-04-03 00:10:30                     1\n",
      "22  2016-04-03 00:11:00                     1\n",
      "23  2016-04-03 00:11:30                     1\n",
      "24  2016-04-03 00:12:00                     1\n",
      "25  2016-04-03 00:12:30                     1\n",
      "26  2016-04-03 00:13:00                     1\n",
      "27  2016-04-03 00:13:30                     1\n",
      "28  2016-04-03 00:14:00                     1\n",
      "29  2016-04-03 00:15:00                     2\n",
      "..                  ...                   ...\n",
      "970 2016-04-03 08:05:00                     8\n",
      "971 2016-04-03 08:05:30                     8\n",
      "972 2016-04-03 08:06:00                     8\n",
      "973 2016-04-03 08:06:30                     8\n",
      "974 2016-04-03 08:07:00                     8\n",
      "975 2016-04-03 08:07:30                     8\n",
      "976 2016-04-03 08:08:00                     8\n",
      "977 2016-04-03 08:08:30                     8\n",
      "978 2016-04-03 08:09:00                     8\n",
      "979 2016-04-03 08:10:00                    17\n",
      "980 2016-04-03 08:10:00                     9\n",
      "981 2016-04-03 08:10:30                     9\n",
      "982 2016-04-03 08:11:00                     9\n",
      "983 2016-04-03 08:11:30                     9\n",
      "984 2016-04-03 08:12:00                     9\n",
      "985 2016-04-03 08:12:30                     9\n",
      "986 2016-04-03 08:13:00                     9\n",
      "987 2016-04-03 08:13:30                     9\n",
      "988 2016-04-03 08:14:00                     9\n",
      "989 2016-04-03 08:15:00                    18\n",
      "990 2016-04-03 08:15:00                     9\n",
      "991 2016-04-03 08:15:30                     9\n",
      "992 2016-04-03 08:16:00                     9\n",
      "993 2016-04-03 08:16:30                     9\n",
      "994 2016-04-03 08:17:00                     9\n",
      "995 2016-04-03 08:17:30                     9\n",
      "996 2016-04-03 08:18:00                     9\n",
      "997 2016-04-03 08:18:30                     9\n",
      "998 2016-04-03 08:19:00                     9\n",
      "999 2016-04-03 08:20:00                    15\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "s = '../data/redondo/test.csv'\n",
    "pattern = re.compile(r\"../data/(?P<city>[a-zA-Z]+?)/(?P<test_file>[a-zA-Z0-9 ]+?).csv\")\n",
    "m = pattern.search(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redondo\n"
     ]
    }
   ],
   "source": [
    "print(m.group('city'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
